<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge;chrome=1">
  <title>Get Started with OpenVINO™ toolkit for Linux* with FPGA Support</title>
  <link href="doxygen.css" rel="stylesheet" type="text/css" />
  <link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>

<body>
  <div id="top">
    <div id="titlearea">
      <div id="projectalign">
       <div id="projectname"><a href="https://software.intel.com/en-us/openvino-toolkit" class="homelink-id">OpenVINO Toolkit</a></div>
      </div>
    </div>
  </div>
  
  
  <div class="header">
    <div class="headertitle">
      <div class="title">Get Started with OpenVINO™ toolkit for Linux* with FPGA support </div>  
    </div>
  </div><!--header-->

  <div class="contents">
      <div class="textblock">
          <h2>About the Intel® Distribution of OpenVINO™ toolkit</h2>
          <p>The Intel® Distribution of OpenVINO™ toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the toolkit extends computer vision (CV) workloads across Intel® hardware, maximizing performance. The Intel® Distribution of OpenVINO™ toolkit includes the Intel® Deep Learning Deployment Toolkit (Intel® DLDT).</p>
          <p>The Intel® Distribution of OpenVINO™ toolkit for Linux* with FPGA support:</p>
          <ul>
          <li>Enables CNN-based deep learning inference on the edge</li>
          <li>Supports heterogeneous execution across an Intel® CPU, Intel® Integrated Graphics, Intel® Movidius™ Neural Compute Stick, Intel® Neural Compute Stick 2 and Intel® Vision Accelerator Design with Intel® Movidius™ VPUs</li>
          <li>Speeds time-to-market via an easy-to-use library of computer vision functions and pre-optimized kernels</li>
          <li>Includes optimized calls for computer vision standards, including OpenCV*, OpenCL™, and OpenVX*</li>
          </ul>
          <h3>Included with the Installation</h3>
          <p>The following components are installed by default:</p>
          <table class="doxtable">
              <tr>
              <th>Component </th><th>Description  </th></tr>
              <tr>
                  <td align="left"><a class="el" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a> </td><td align="left">This tool imports, converts, and optimizes models, which were trained in popular frameworks, to a format usable by Intel tools, especially the Inference Engine. <br />
                    <blockquote class="doxtable"><strong>NOTE:</strong> Popular frameworks include Caffe*, TensorFlow*, MXNet*, and ONNX*.</blockquote> </td></tr>
                  <tr>
                  <td align="left"><a class="el" href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html">Inference Engine</a> </td><td align="left">This is the engine that runs a deep learning model. It includes a set of libraries for an easy inference integration into your applications. </td></tr>
              <tr>
              <td>Drivers and runtimes for OpenCL™ version 2.1 </td><td>Enables OpenCL on the GPU/CPU for Intel® processors </td></tr>
              <tr>
              <td>Intel® Media SDK </td><td>Offers access to hardware accelerated video codecs and frame processing </td></tr>
              <tr>
              <td>Pre-compiled FPGA bitstream samples </td><td>Pre-compiled bitstream samples for the Intel® Arria® 10 GX FPGA Development Kit, Intel® Programmable Acceleration Card with Intel® Arria® 10 GX FPGA and Intel® Vision Accelerator Design with an Intel® Arria 10 FPGA (preview) </td></tr>
              <tr>
              <td>Intel® FPGA SDK for OpenCL™ software technology </td><td>The Intel® FPGA RTE for OpenCL™ provides utilities, host runtime libraries, drivers, and RTE-specific libraries and files </td></tr>
              <tr>
              <td><a href="https://docs.opencv.org/">OpenCV</a> </td><td>OpenCV* community version compiled for Intel® hardware. </td></tr>
              <tr>
              <td>OpenVX* </td><td>Intel's implementation of OpenVX* optimized for running on Intel® hardware (CPU, GPU, IPU) </td></tr>
              <tr>
              <td>Pre-trained models </td><td>Set of Intel's pre-trained models for learning and demo purposes or to develop deep learning software. </td></tr>
              <tr>
                  <td align="left">Sample Applications </td><td align="left">A set of simple console applications demonstrating how to use the Inference Engine in your applications. For additional information about building and running the samples, refer to the <a class="el" href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Samples_Overview.html">Inference Engine Samples Overview</a>. </td></tr>
          </table>
          <h2>System Requirements</h2>
          <p><b>The development and target platforms have the same requirements, but you can select different components during the installation, based on your intended use.</b></p>
          <p><b>Hardware</b></p>
          <ul>
              <li>6th-8th Generation Intel® Core™</li>
              <li>Intel® Xeon® v5 family</li>
              <li>Intel® Xeon® v6 family</li>
              <li>Intel® Pentium® processor N4200/5, N3350/5, N3450/5 with Intel® HD Graphics</li>
              <li>Intel® Movidius™ Neural Compute Stick</li>
              <li>Intel® Neural Compute Stick 2  </li>
              <li>Intel® Arria® 10 GX FPGA Development Kit or the Intel® Programmable Acceleration Card with Intel® Arria® 10 GX FPGA</li>
              <li>Intel® Vision Accelerator Design with an Intel® Arria 10 FPGA (preview)</li>
          </ul>
          <p><b>Processor Notes:</b></p>
          <ul>
          <li>Processor graphics are not included in all processors. See <a href="https://ark.intel.com/#@Processors">Processors specifications</a> for information about your processor.</li>
          <li>A chipset that supports processor graphics is required if you're using an Intel Xeon processor. See <a href="https://ark.intel.com/#@Chipsets">Chipset specifications</a> for information about your chipset.</li>
          </ul>
          <p><b>Operating Systems:</b></p>
          <ul>
            <li>Ubuntu* 16.04.x long-term support (LTS), 64-bit</li>
            <li>CentOS* 7.4, 64-bit</li>
            <li>Yocto Project* Poky Jethro* v2.0.3, 64-bit (for target only)
          </li>
          </ul>

          <h2>Install Intel® Distribution of OpenVINO™ toolkit</h2>
          <p>To install and configure the Intel® Distribution of OpenVINO™ toolkit for Linux with FPGA support, follow the instructions from the <a href="https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_linux_fpga.html">Installation Guide</a></p>

          <blockquote class="doxtable">
          <p><b>IMPORTANT</b>:<br />
          </p><ul>
          <li>All steps in this guide are required unless otherwise stated.<br />
          </li>
          <li>In addition to the downloaded package, you must install dependencies and complete configuration steps. </li>
          </ul>
          </blockquote>

          <h2>Build and Run Sample Applications</h2>
          <p>To build and run Inference Engine sample applications and demos, refer to the <a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Samples_Overview.html">Inference Engine Samples Overview.</a></p>

          <h2>Pre-Trained Models</h2>
          <p>To learn about pre-trained models for the OpenVINO™ toolkit, refer to:
          <ul>
            <li><a href="https://docs.openvinotoolkit.org/latest/_docs_docs_Pre_Trained_Models.html">latest stable pre-trained models documentation</a> OR</li>
            <li><a href="https://github.com/opencv/open_model_zoo/blob/master/intel_models/index.md">most recent models documentation.</a></li>
          </ul>
          
          <h2>Documentation</h2>
          <p>Learn the OpenVINO documentation and how-to's at <a href="https://docs.openvinotoolkit.org">https://docs.openvinotoolkit.org</a>.</p>
      </div>
  </div>
</body>
</html>
